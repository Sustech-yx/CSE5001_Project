Parameters:
  BATCH_SIZE=50
  CUDA=0
  DATASET=
  DROPOUT=0.3
  HIDDEN_DIM=300
  LR=0.001
  NUM_BATCHES=100
  NUM_CLUSTERS=2
  NUM_EPOCHS=1000
  PATIENCE=5
  SEED=0
  SRC_DATASET=MNIST_0123456789_0123456789_10
  THRES=0.3
  TRANSFER_EBD=False
  WEIGHT_DECAY=0.01
24/01/06 22:39:54 Loading source task MNIST_0123456789_0123456789_10
file number: 9900
Predict then Interpolate (PI)

24/01/06 22:40:22 Start training classifier on train env 0
PI env 0 epoch   0 train acc 0.8294 loss 0.7876 val acc 0.8024 loss 0.8992
PI env 0 epoch   1 train acc 0.8916 loss 0.5519 val acc 0.7912 loss 0.9245
PI env 0 epoch   2 train acc 0.8870 loss 0.5643 val acc 0.8070 loss 0.8389
PI env 0 epoch   3 train acc 0.8896 loss 0.5582 val acc 0.8078 loss 0.8367
PI env 0 epoch   4 train acc 0.8940 loss 0.5425 val acc 0.8056 loss 0.9044
PI env 0 epoch   5 train acc 0.8860 loss 0.5810 val acc 0.7982 loss 0.9206
PI env 0 epoch   6 train acc 0.8916 loss 0.5584 val acc 0.7956 loss 0.9505
PI env 0 epoch   7 train acc 0.8916 loss 0.5476 val acc 0.7990 loss 0.9163
PI env 0 epoch   8 train acc 0.8864 loss 0.5568 val acc 0.7944 loss 0.8480

24/01/06 22:40:56 Start training classifier on train env 1
PI env 1 epoch   0 train acc 0.7366 loss 1.0970 val acc 0.8876 loss 0.5173
PI env 1 epoch   1 train acc 0.7750 loss 0.8755 val acc 0.8892 loss 0.5089
PI env 1 epoch   2 train acc 0.7700 loss 0.8607 val acc 0.8706 loss 0.5664
PI env 1 epoch   3 train acc 0.7662 loss 0.8806 val acc 0.8612 loss 0.5327
PI env 1 epoch   4 train acc 0.7862 loss 0.8267 val acc 0.8842 loss 0.5124
PI env 1 epoch   5 train acc 0.7840 loss 0.8319 val acc 0.8768 loss 0.5831
PI env 1 epoch   6 train acc 0.7804 loss 0.8482 val acc 0.8656 loss 0.5613

24/01/06 22:41:29 Use DRO to learn a robust source classifier
epoch   0 train avg 0.4231 worst 0.3248 loss 1.9007 2.0392 val acc 0.6432 loss 1.4843
epoch   1 train avg 0.5609 worst 0.4494 loss 1.6190 1.8333 val acc 0.6354 loss 1.5025
epoch   2 train avg 0.5751 worst 0.4764 loss 1.5788 1.7787 val acc 0.6875 loss 1.3859
epoch   3 train avg 0.5955 worst 0.4968 loss 1.5289 1.7555 val acc 0.6864 loss 1.3796
epoch   4 train avg 0.5917 worst 0.5012 loss 1.5261 1.7183 val acc 0.7085 loss 1.2638
epoch   5 train avg 0.5996 worst 0.5098 loss 1.5072 1.7244 val acc 0.6738 loss 1.3035
epoch   6 train avg 0.5999 worst 0.5074 loss 1.4987 1.7243 val acc 0.6497 loss 1.3843
epoch   7 train avg 0.6039 worst 0.5250 loss 1.4966 1.7022 val acc 0.6776 loss 1.3424
epoch   8 train avg 0.6044 worst 0.5240 loss 1.4855 1.6748 val acc 0.6748 loss 1.3654
epoch   9 train avg 0.6127 worst 0.5336 loss 1.4721 1.6652 val acc 0.7203 loss 1.1961
epoch  10 train avg 0.6229 worst 0.5234 loss 1.4444 1.6761 val acc 0.7143 loss 1.1955
epoch  11 train avg 0.6241 worst 0.5280 loss 1.4414 1.6545 val acc 0.7088 loss 1.2562
epoch  12 train avg 0.6243 worst 0.5462 loss 1.4537 1.6649 val acc 0.6951 loss 1.3921
epoch  13 train avg 0.6244 worst 0.5304 loss 1.4490 1.6593 val acc 0.6957 loss 1.2965
epoch  14 train avg 0.6184 worst 0.5402 loss 1.4560 1.6422 val acc 0.6829 loss 1.2574
epoch  15 train avg 0.6273 worst 0.5398 loss 1.4426 1.6476 val acc 0.6925 loss 1.2851
epoch  16 train avg 0.6238 worst 0.5408 loss 1.4497 1.6506 val acc 0.6936 loss 1.3620
epoch  17 train avg 0.6325 worst 0.5414 loss 1.4121 1.6262 val acc 0.7137 loss 1.2404
24/01/06 22:44:25 Finished DRO on the source task

24/01/06 22:44:25 Evaluating on the test environment for MNIST_0123456789_0123456789_10
Test results: acc 0.6800 loss 1.5177 

24/01/06 22:44:26 Output prediction for MNIST_0123456789_0123456789_10